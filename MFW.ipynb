{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqfuellYNOGU"
      },
      "source": [
        "# Load Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Gh_FnbciWX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ndcg_score\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej50v9G3c7F7"
      },
      "source": [
        "# Load, Preprocess, Split - Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvpX8odr9rKf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data():\n",
        "  # Set the URL and file name for the dataset\n",
        "  url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "  filename = 'movielens.zip'\n",
        "\n",
        "  # Download the dataset\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Extract the dataset\n",
        "  with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "      zip_ref.extractall()\n",
        "\n",
        "  # Load the ratings.csv and movies.csv files into pandas dataframes\n",
        "  ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, names=['userId', 'movieId', 'rating', 'timestamp'], engine='python')\n",
        "  movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, names=['movieId', 'title', 'genres'], engine='python', encoding='latin-1')\n",
        "\n",
        "  return ratings, movies\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYMOjMIEmHqe",
        "outputId": "9fbcda15-eb91-4896-c917-5ce46414c8b5"
      },
      "outputs": [],
      "source": [
        "ratings, movies = load_data()\n",
        "\n",
        "# Print the first few rows of each dataframe\n",
        "print('Ratings dataframe:')\n",
        "print(ratings.head())\n",
        "print('\\nMovies dataframe:')\n",
        "print(movies.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qgSE8tojMhGV",
        "outputId": "31bee567-7f7a-4526-9e35-2194ed6e6c1a"
      },
      "outputs": [],
      "source": [
        "# get the distribution of ratings\n",
        "ratings_dist = ratings['rating'].value_counts().sort_index()\n",
        "\n",
        "# create the bar chart\n",
        "fig, ax = plt.subplots() # create a figure and axis object\n",
        "bars = ax.bar(ratings_dist.index, ratings_dist.values)\n",
        "\n",
        "# add rating values on top of bars\n",
        "for bar, freq in zip(bars, ratings_dist.values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, height, freq,\n",
        "            ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# add some labels and title\n",
        "ax.set_xlabel('Rating')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Distribution of Movie Ratings')\n",
        "\n",
        "# show the bar chart\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKqMQE5VPA5e",
        "outputId": "9a1b5a8e-4719-4407-b437-6bd5987f8d93"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Calculate statistics dynamically\n",
        "num_movies = len(movies)\n",
        "num_users = len(ratings['userId'].unique())\n",
        "num_ratings = len(ratings)\n",
        "avg_ratings_per_user = ratings.groupby('userId').size().mean()\n",
        "avg_ratings_per_movie = ratings.groupby('movieId').size().mean()\n",
        "\n",
        "# Format the values\n",
        "num_movies_str = \"{:,}\".format(num_movies)\n",
        "num_users_str = \"{:,}\".format(num_users)\n",
        "num_ratings_str = \"{:,}\".format(num_ratings)\n",
        "avg_ratings_per_user_str = \"{:.2f}\".format(avg_ratings_per_user)\n",
        "avg_ratings_per_movie_str = \"{:.2f}\".format(avg_ratings_per_movie)\n",
        "\n",
        "# Create the table\n",
        "data = [['Number of Movies', num_movies_str],\n",
        "        ['Number of Users', num_users_str],\n",
        "        ['Number of Ratings', num_ratings_str],\n",
        "        ['Average Ratings per User', avg_ratings_per_user_str],\n",
        "        ['Average Ratings per Movie', avg_ratings_per_movie_str]]\n",
        "df = pd.DataFrame(data, columns=['Statistic', 'Value'])\n",
        "\n",
        "# Show the table\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U1sYoTqXUbaw",
        "outputId": "fd70a29b-ca1d-430a-8ad7-73b5f7b27f94"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "cRfswiHjWk9p",
        "outputId": "7c49a12a-18a8-4c07-d17b-a0375c9f0332"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "genres = movies['genres'].str.split('|', expand=True)\n",
        "genre_counts = genres.stack().value_counts()\n",
        "\n",
        "# create the pie chart\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(genre_counts.values, labels=genre_counts.index)\n",
        "\n",
        "# set the title\n",
        "ax.set_title('Genre Distribution of Movies')\n",
        "\n",
        "# show the chart\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB7786rf-1Sb"
      },
      "outputs": [],
      "source": [
        "# Encode the user and movie IDs\n",
        "user_encoder = {u: i for i, u in enumerate(ratings['userId'].unique())}\n",
        "movie_encoder = {m: i for i, m in enumerate(ratings['movieId'].unique())}\n",
        "ratings['userId'] = ratings['userId'].apply(lambda x: user_encoder[x])\n",
        "ratings['movieId'] = ratings['movieId'].apply(lambda x: movie_encoder[x])\n",
        "\n",
        "\n",
        "# Map the movie IDs to their titles\n",
        "movie_titles = {}\n",
        "for movie_id in movie_encoder:\n",
        "    title = movies.loc[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    movie_titles[movie_encoder[movie_id]] = title\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train, val = train_test_split(ratings, test_size=0.4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pTp1jMAgDK9A",
        "outputId": "6b63e1a3-8ed6-404c-bc12-394981ba2539"
      },
      "outputs": [],
      "source": [
        "ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cb5RuFD6uuJ"
      },
      "source": [
        "# Movie Lens Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wpRUPcw6t1M"
      },
      "outputs": [],
      "source": [
        "# Define the Movielens dataset\n",
        "class MovielensDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.user_ids = data['userId'].values\n",
        "        self.movie_ids = data['movieId'].values\n",
        "        self.ratings = data['rating'].values\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.user_ids[idx], self.movie_ids[idx]), self.ratings[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3DNQVl5tSul"
      },
      "source": [
        "# Matrix Factorization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMxNHh4NtRrb"
      },
      "outputs": [],
      "source": [
        "# Define the matrix factorization model\n",
        "class MatrixFactorizationModel(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_movies, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = torch.nn.Embedding(num_users, embedding_dim)\n",
        "        self.movie_embeddings = torch.nn.Embedding(num_movies, embedding_dim)\n",
        "        self.bias_user = torch.nn.Embedding(num_users, 1)\n",
        "        self.bias_movie = torch.nn.Embedding(num_movies, 1)\n",
        "        self.global_bias = torch.nn.Parameter(torch.tensor(ratings['rating'].mean()))\n",
        "        \n",
        "    def forward(self, user_ids, movie_ids):\n",
        "        user_embeds = self.user_embeddings(user_ids)\n",
        "        movie_embeds = self.movie_embeddings(movie_ids)\n",
        "        user_bias = self.bias_user(user_ids)\n",
        "        movie_bias = self.bias_movie(movie_ids)\n",
        "        dot_product = torch.sum(user_embeds * movie_embeds, dim = 1)\n",
        "        output = dot_product + user_bias.squeeze() + movie_bias.squeeze() + self.global_bias\n",
        "        return output\n",
        "\n",
        "# Define the training loop\n",
        "def train_model(model, train_loader,loss_list, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch_idx, (inputs, ratings) in enumerate(train_loader):\n",
        "            user_ids = inputs[0]\n",
        "            movie_ids = inputs[1]\n",
        "            ratings = ratings.float()\n",
        "            outputs = model(user_ids, movie_ids)\n",
        "            loss = criterion(outputs, ratings)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "        loss_list.append(train_loss)\n",
        "        print('Epoch: {} Train Loss: {:.4f}'.format(epoch+1, train_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LH45SFZdRVv"
      },
      "source": [
        "# Create Data Loader for train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__--GyZB_aaE"
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset and data loaders\n",
        "train_dataset = MovielensDataset(train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataset = MovielensDataset(val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldxq7uy-ddOk"
      },
      "source": [
        "# Build & Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc14eItn_wnd",
        "outputId": "605df756-bc2e-4d09-cea4-18ba27b4a7d0"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and define the loss and optimizer\n",
        "model = MatrixFactorizationModel(num_users=len(ratings['userId'].unique()), \n",
        "                                 num_movies=len(ratings['movieId'].unique()), \n",
        "                                 embedding_dim=64)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_list = []\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, loss_list, criterion, optimizer, num_epochs=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tchWUn1Xac1g"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWHiHcJaauYd"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU9XwYzqduiQ"
      },
      "source": [
        "# Training loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "6j6V-MVfc-iL",
        "outputId": "3daf820a-cb7a-488a-b926-d50e61d9e2fb"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the loss values\n",
        "ax.plot(loss_list)\n",
        "\n",
        "# Set axis labels and title\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_title('Training Loss')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iz8_AF2jTsZ"
      },
      "source": [
        "# Compute MSE, RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL0uXjpXkiaX",
        "outputId": "146f190e-2510-4328-d3bb-3ede0a50f06e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model_output_list = []\n",
        "target_rating_list = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(val_loader): \n",
        "        model_output = model(batched_data[0][0], \n",
        "                       batched_data[0][1])\n",
        "        \n",
        "        model_output_list.append(model_output.sum().item() / len(batched_data[0][0]) )\n",
        "\n",
        "        target_rating = batched_data[1]\n",
        "        \n",
        "        target_rating_list.append(target_rating.sum().item() / len(batched_data[0][0]))\n",
        "\n",
        "        # print(f\"model_output: {model_output}, target_rating: {target_rating}\")\n",
        "\n",
        "\n",
        "# squared If True returns MSE value, if False returns RMSE value.\n",
        "rmse = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
        "mse = mean_squared_error(target_rating_list, model_output_list, squared=True)\n",
        "print(f\"mse: {mse}\")\n",
        "print(f\"rmse: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "P3_RO4MmCBP2",
        "outputId": "0fdb24ba-f7fc-42bf-b3b4-b72169121b1a"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# create the data\n",
        "data = [['', 'Loss Function'],\n",
        "        ['MSE', mse],\n",
        "        ['RMSE', rmse]]\n",
        "\n",
        "# create the table\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.axis('off')\n",
        "ax.axis('tight')\n",
        "table = ax.table(cellText=data, colLabels=None, cellLoc='center', loc='center', fontsize=14, cellColours=[['lightgray'] * 2, [None, 'lightgray'], [None, 'lightgray']])\n",
        "\n",
        "# adjust cell widths and heights\n",
        "table.auto_set_column_width(col=list(range(2)))\n",
        "table.scale(1, 2)\n",
        "\n",
        "# show the table\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnyP9U8XjIP"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNLR19JwXqGK"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, val_loader, threshold):\n",
        "    \"\"\"Compute recall, precision, f_score, and ndcg of the model on the validation set.\"\"\"\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    ndcg = 0\n",
        "    \n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Unpack the batch elements\n",
        "            user_ids = batch[0][0]\n",
        "            movie_ids = batch[0][1]\n",
        "            ratings = batch[1]\n",
        "\n",
        "            # Predict the ratings for the validation set\n",
        "            preds = model(user_ids, movie_ids).squeeze()\n",
        "            \n",
        "            # Compute the binary predictions using the threshold\n",
        "            binary_preds = torch.where(torch.logical_and(preds >= threshold, preds <= 5), torch.ones_like(preds), torch.zeros_like(preds))\n",
        "            \n",
        "            binary_movie_rating = torch.where(ratings >= threshold, torch.ones_like(preds), torch.zeros_like(preds))\n",
        "            # Compute the true positives, false positives, and false negatives\n",
        "            true_positives += ((binary_preds == 1) & (binary_movie_rating == 1)).sum().item()\n",
        "            false_positives += ((binary_preds == 1) & (binary_movie_rating == 0)).sum().item()\n",
        "            false_negatives += ((binary_preds == 0) & (binary_movie_rating == 1)).sum().item()\n",
        "\n",
        "            \n",
        "            # Compute the NDCG score\n",
        "            ndcg += ndcg_score(np.expand_dims(ratings, axis=0), np.expand_dims(preds, axis=0), k=10).item()\n",
        "    \n",
        "    # Compute the recall, precision, f_score, and ndcg\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    f_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
        "    ndcg /= len(val_loader)\n",
        "    \n",
        "    return recall, precision, f_score, ndcg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n0OXedCdzii"
      },
      "source": [
        "# Compute Recall, Precision, F_score, Ndcg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZZ8yI7wEDZ0",
        "outputId": "6b864afc-a2b1-4644-a8ac-f63f81e91586"
      },
      "outputs": [],
      "source": [
        "recall, precision, f_score, ndcg = evaluate_model(model, val_loader, 3.5)\n",
        "print(f\"Recall:  {recall}, Precision: {precision}, F_score: {f_score}, Ndcg: {ndcg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "jhpJ7fmVIK3h",
        "outputId": "043d4fee-f32b-4490-cbc8-f2032f59b363"
      },
      "outputs": [],
      "source": [
        "# create the data\n",
        "data = [['', 'Evaluation Metrics'],\n",
        "        ['Recall', recall],\n",
        "        ['Precision', precision],\n",
        "        ['F_Score', f_score],\n",
        "        ['NDCG', ndcg]]\n",
        "\n",
        "# create the table\n",
        "fig, ax = plt.subplots(figsize=(4, 3)) # create a figure and axis object\n",
        "colors = [['lightgray']*2, [None, 'lightgray'], [None, 'lightgray'], [None, 'lightgray'], [None, 'lightgray']]\n",
        "table = ax.table(cellText=data, colLabels=None, cellLoc='center', loc='center', fontsize=14, cellColours = colors)\n",
        "\n",
        "# adjust cell widths and heights\n",
        "table.auto_set_column_width(col=list(range(2)))\n",
        "table.scale(1, 2)\n",
        "\n",
        "# remove borders\n",
        "ax.axis('off')\n",
        "\n",
        "# show the table\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_1uI1S6bnRb"
      },
      "source": [
        "# Compute Recall@K, Precision@K\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b127d77",
        "outputId": "23acf3d5-79b3-41eb-de08-11af32d25fdd"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# a dict that stores a list of predicted rating and actual rating pair for each user \n",
        "user_est_true = defaultdict(list)\n",
        "\n",
        "# iterate through the validation data to build the user-> [(y1, y1_hat), (y2, y2_hat)...]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(val_loader): \n",
        "        users = batched_data[0][0]\n",
        "        movies = batched_data[0][1]\n",
        "        ratings = batched_data[1]\n",
        "\n",
        "        \n",
        "        model_output = model(batched_data[0][0], batched_data[0][1])\n",
        "\n",
        "        for i in range(len(users)):\n",
        "            user_id = users[i].item()\n",
        "            movie_id = movies[i].item() \n",
        "            pred_rating = model_output[i].item()\n",
        "            true_rating = ratings[i].item()\n",
        "            \n",
        "            print(f\"{user_id}, {movie_id}, {pred_rating}, {true_rating}\")\n",
        "            user_est_true[user_id].append((pred_rating, true_rating, movie_id))            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnuP0GUa-3um"
      },
      "outputs": [],
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    recommended_movies = dict()\n",
        "    k = 10\n",
        "\n",
        "    threshold = 3.5\n",
        "\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value. \n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        top_k_movies = [movie_titles[movie_id] for (est, true_r, movie_id) in user_ratings[:k] if est >= threshold and est <= 5]\n",
        "\n",
        "        # Add the recommended movies to the dictionary for this user\n",
        "        recommended_movies[uid] = top_k_movies[:k]\n",
        " \n",
        "        # get the number of actual relevant item\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r,_) in user_ratings)\n",
        "\n",
        "        # get the number of recommended item that are predicted relevent and within topk\n",
        "        n_rec_k = sum((est >= threshold) for (est, _, _) in user_ratings[:k])\n",
        "\n",
        "        # get the number of recommented item that' is also actually relevant within topk\n",
        "        n_rel_and_rec_k = sum(\n",
        "            ((true_r >= threshold) and (est >= threshold))\n",
        "            for (est, true_r, _) in user_ratings[:k]\n",
        "        )\n",
        "\n",
        "        # print(f\"uid {uid},  n_rel {n_rel}, n_rec_k {n_rec_k}, n_rel_and_rec_k {n_rel_and_rec_k}\")\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of   relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgcK9qtZ_CnN",
        "outputId": "6a3eeddd-5779-4765-a6f6-15eed5385c2e"
      },
      "outputs": [],
      "source": [
        "# Precision and recall can then be averaged over all users\n",
        "print(f\"precision @ {k}: {sum(prec for prec in precisions.values()) / len(precisions)}\")\n",
        "\n",
        "print(f\"recall @ {k} : {sum(rec for rec in recalls.values()) / len(recalls)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-vFiHRrBQ04"
      },
      "source": [
        "# Recommend Movies to User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctIgbWys4z8D",
        "outputId": "02a7bf91-e188-43d0-ad14-406b050c1369"
      },
      "outputs": [],
      "source": [
        "recommended_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM7txO0jAE5x",
        "outputId": "7748b336-cdd2-427e-da57-8c7db21489f4"
      },
      "outputs": [],
      "source": [
        "# Sample User\n",
        "user_id = 478\n",
        "recommended_movies[user_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YpQlDDX-CN6"
      },
      "outputs": [],
      "source": [
        "def recommend_unwatched_movies(model, user_encoder, movie_encoder, user_id, threshold, top_n=10):\n",
        "    \"\"\"Recommend top N movies to the given user that they have not yet watched.\"\"\"\n",
        "    \n",
        "    # Get the list of all movies\n",
        "    all_movies = np.array(list(movie_encoder.keys()))\n",
        "    \n",
        "    # Get the list of movies rated by the user\n",
        "    rated_movies = ratings[ratings['userId'] == user_id]['movieId'].values\n",
        "    \n",
        "    # Get the list of movies the user has not watched\n",
        "    unwatched_movies = np.setdiff1d(all_movies, rated_movies)\n",
        "\n",
        "    # Get the encoded user ID\n",
        "    encoded_user_id = user_encoder[user_id]\n",
        "  \n",
        "    # Get the predicted ratings for the user and unwatched movies\n",
        "    recommended_movie_id = []\n",
        "    for movie_id in unwatched_movies:\n",
        "        encoded_movie_id = movie_encoder[movie_id]\n",
        "        predicted_rating = model(torch.LongTensor([encoded_user_id]), torch.LongTensor([encoded_movie_id])).item()\n",
        "        if (predicted_rating >= threshold and predicted_rating <= 5.0):\n",
        "            recommended_movie_id.append((predicted_rating, movie_id))\n",
        "    \n",
        "    # Sort the unwatched movies by predicted rating and recommend the top N\n",
        "    recommended_movie_id.sort(key = lambda x : x[0], reverse=True)\n",
        "    top_movies = [movie_titles[movie_encoder[movie_id]] for _, movie_id in recommended_movie_id[:top_n]]\n",
        "    \n",
        "    return top_movies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxt7iYyoPrO3"
      },
      "outputs": [],
      "source": [
        "# Load the Movielens dataset\n",
        "ratings, movies = load_data()\n",
        "\n",
        "user_encoder = {u: i for i, u in enumerate(ratings['userId'].unique())}\n",
        "movie_encoder = {m: i for i, m in enumerate(ratings['movieId'].unique())}\n",
        "ratings['userId'] = ratings['userId'].apply(lambda x: user_encoder[x])\n",
        "ratings['movieId'] = ratings['movieId'].apply(lambda x: movie_encoder[x])\n",
        "\n",
        "\n",
        "# Map the movie IDs to their titles\n",
        "movie_titles = {}\n",
        "for movie_id in movie_encoder:\n",
        "    title = movies.loc[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    genres = movies.loc[movies['movieId'] == movie_id]['genres'].values[0]\n",
        "    movie_titles[movie_encoder[movie_id]] = (title, genres)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTFX5OjE9ac_",
        "outputId": "d742d1b3-daa9-438d-95ad-8c10e1434aba"
      },
      "outputs": [],
      "source": [
        "user_id = 478\n",
        "print('User ID:', user_id, recommend_unwatched_movies(model, user_encoder, movie_encoder, user_id, 3.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Iw-_VsqLYuW2",
        "outputId": "9d085a96-ead6-425b-f7fd-605a568c4990"
      },
      "outputs": [],
      "source": [
        "user_id = 477\n",
        "rec_movies = dict(recommend_unwatched_movies(model, user_encoder, movie_encoder, user_id, 3.5))\n",
        "pd.DataFrame({\"Movie Title\": rec_movies.keys(), \"Genre\": rec_movies.values()})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
